{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OWL-ViT predictions\n",
    "* To get the labels for each image predicted by OWL-ViT that would be later used by ProbCover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/clip/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2data=\"/home/ubuntu/mmdetection_od/mmdetection/data/coco/images/train2017\"\n",
    "path2json=\"/home/ubuntu/mmdetection_od/mmdetection/data/coco/annotations/instances_train2017.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=15.71s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CocoDetection(root=path2data, annFile=path2json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the indices for the annotated images \n",
    "indices_annotated_images=[]\n",
    "#reading the filenames.txt file \n",
    "with open('/home/ubuntu/master_thesis/covering_lens/TypiClust/deep-al/pycls/datasets/annotated_train_images_indices_2017.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        indices_annotated_images.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to int\n",
    "int_indices_annotated_images = [int(x) for x in indices_annotated_images]\n",
    "dataset=torch.utils.data.Subset(train_dataset, int_indices_annotated_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117266"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/opt/conda/envs/clip/lib/python3.8/site-packages/transformers/models/owlvit/image_processing_owlvit.py:421: FutureWarning: `post_process` is deprecated and will be removed in v5 of Transformers, please use `post_process_object_detection` instead, with `threshold=0.` for equivalent results.\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "image_features = []\n",
    "image_file_names=[]\n",
    "\n",
    "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "\n",
    "#class of ms coco\n",
    "texts =  [\n",
    "    'human', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
    "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "dict_image = {}\n",
    "#for idx in tqdm(range(len(dataset))):\n",
    "for idx in tqdm(range(100000,len(dataset))):\n",
    "    # get the image and its annotations\n",
    "\n",
    "\n",
    "\n",
    "    img, target = dataset[idx]\n",
    "\n",
    "    image_id = target[0]['image_id']\n",
    "    image_info = train_dataset.coco.loadImgs(image_id)[0]\n",
    "    image_file_name =image_info['file_name'] \n",
    "\n",
    "    dict_image[image_file_name]={}\n",
    "    dict_image[image_file_name]['label'] =[]\n",
    "    dict_image[image_file_name]['score']=[]\n",
    "\n",
    "    inputs = processor(text=texts, images=img, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Target image sizes (height, width) to rescale box predictions [batch_size, 2]\n",
    "    target_sizes = torch.Tensor([img.size[::-1]])\n",
    "    # Convert outputs (bounding boxes and class logits) to COCO API\n",
    "    results = processor.post_process(outputs=outputs, target_sizes=target_sizes)\n",
    "\n",
    "    i = 0  # Retrieve predictions for the first image for the corresponding text queries\n",
    "    text = texts[i]\n",
    "    boxes, scores, labels = results[i][\"boxes\"], results[i][\"scores\"], results[i][\"labels\"]\n",
    "\n",
    "    # Print detected objects and rescaled box coordinates\n",
    "    score_threshold = 0.1\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        if score >= score_threshold:\n",
    "            #print(f\"Detected {texts[label]} with confidence {round(score.item(), 3)} at location {box}\")\n",
    "          \n",
    "            dict_image[image_file_name]['label'].append(texts[label])\n",
    "            dict_image[image_file_name]['score'].append(round(score.item(), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_mscoco=pd.DataFrame(dict_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000000496053.jpg</th>\n",
       "      <th>000000496058.jpg</th>\n",
       "      <th>000000496059.jpg</th>\n",
       "      <th>000000496064.jpg</th>\n",
       "      <th>000000496065.jpg</th>\n",
       "      <th>000000496073.jpg</th>\n",
       "      <th>000000496078.jpg</th>\n",
       "      <th>000000496081.jpg</th>\n",
       "      <th>000000496089.jpg</th>\n",
       "      <th>000000496090.jpg</th>\n",
       "      <th>...</th>\n",
       "      <th>000000581887.jpg</th>\n",
       "      <th>000000581899.jpg</th>\n",
       "      <th>000000581900.jpg</th>\n",
       "      <th>000000581903.jpg</th>\n",
       "      <th>000000581904.jpg</th>\n",
       "      <th>000000581906.jpg</th>\n",
       "      <th>000000581909.jpg</th>\n",
       "      <th>000000581913.jpg</th>\n",
       "      <th>000000581921.jpg</th>\n",
       "      <th>000000581929.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>[tv, tv, tv, handbag, human, tv, remote, remot...</td>\n",
       "      <td>[surfboard, human, surfboard, boat, surfboard,...</td>\n",
       "      <td>[traffic light, traffic light, bus, traffic li...</td>\n",
       "      <td>[microwave, microwave, clock, clock, clock, bo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[train]</td>\n",
       "      <td>[bird, sports ball]</td>\n",
       "      <td>[truck, horse, horse, horse]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[traffic light, car, car, car, truck, car, car...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[chair, chair, handbag, chair, motorcycle]</td>\n",
       "      <td>[bottle]</td>\n",
       "      <td>[clock, handbag]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[boat, boat, boat, boat]</td>\n",
       "      <td>[donut, donut, donut]</td>\n",
       "      <td>[human, snowboard]</td>\n",
       "      <td>[horse, horse, horse, horse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>[0.468, 0.478, 0.389, 0.126, 0.1, 0.469, 0.143...</td>\n",
       "      <td>[0.142, 0.104, 0.207, 0.127, 0.124, 0.389, 0.1...</td>\n",
       "      <td>[0.39, 0.407, 0.244, 0.104, 0.186, 0.137, 0.12...</td>\n",
       "      <td>[0.138, 0.16, 0.13, 0.102, 0.112, 0.135, 0.134...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.18]</td>\n",
       "      <td>[0.114, 0.134]</td>\n",
       "      <td>[0.129, 0.103, 0.189, 0.262]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.354, 0.106, 0.18, 0.127, 0.185, 0.125, 0.17...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.101, 0.125, 0.161, 0.184, 0.3]</td>\n",
       "      <td>[0.113]</td>\n",
       "      <td>[0.534, 0.118]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.109, 0.107, 0.2, 0.18]</td>\n",
       "      <td>[0.276, 0.242, 0.128]</td>\n",
       "      <td>[0.129, 0.464]</td>\n",
       "      <td>[0.654, 0.145, 0.6, 0.111]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 17266 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        000000496053.jpg  \\\n",
       "label  [tv, tv, tv, handbag, human, tv, remote, remot...   \n",
       "score  [0.468, 0.478, 0.389, 0.126, 0.1, 0.469, 0.143...   \n",
       "\n",
       "                                        000000496058.jpg  \\\n",
       "label  [surfboard, human, surfboard, boat, surfboard,...   \n",
       "score  [0.142, 0.104, 0.207, 0.127, 0.124, 0.389, 0.1...   \n",
       "\n",
       "                                        000000496059.jpg  \\\n",
       "label  [traffic light, traffic light, bus, traffic li...   \n",
       "score  [0.39, 0.407, 0.244, 0.104, 0.186, 0.137, 0.12...   \n",
       "\n",
       "                                        000000496064.jpg 000000496065.jpg  \\\n",
       "label  [microwave, microwave, clock, clock, clock, bo...               []   \n",
       "score  [0.138, 0.16, 0.13, 0.102, 0.112, 0.135, 0.134...               []   \n",
       "\n",
       "      000000496073.jpg     000000496078.jpg              000000496081.jpg  \\\n",
       "label          [train]  [bird, sports ball]  [truck, horse, horse, horse]   \n",
       "score           [0.18]       [0.114, 0.134]  [0.129, 0.103, 0.189, 0.262]   \n",
       "\n",
       "      000000496089.jpg 000000496090.jpg  ...  \\\n",
       "label               []               []  ...   \n",
       "score               []               []  ...   \n",
       "\n",
       "                                        000000581887.jpg 000000581899.jpg  \\\n",
       "label  [traffic light, car, car, car, truck, car, car...               []   \n",
       "score  [0.354, 0.106, 0.18, 0.127, 0.185, 0.125, 0.17...               []   \n",
       "\n",
       "                                 000000581900.jpg 000000581903.jpg  \\\n",
       "label  [chair, chair, handbag, chair, motorcycle]         [bottle]   \n",
       "score           [0.101, 0.125, 0.161, 0.184, 0.3]          [0.113]   \n",
       "\n",
       "       000000581904.jpg 000000581906.jpg           000000581909.jpg  \\\n",
       "label  [clock, handbag]               []   [boat, boat, boat, boat]   \n",
       "score    [0.534, 0.118]               []  [0.109, 0.107, 0.2, 0.18]   \n",
       "\n",
       "            000000581913.jpg    000000581921.jpg              000000581929.jpg  \n",
       "label  [donut, donut, donut]  [human, snowboard]  [horse, horse, horse, horse]  \n",
       "score  [0.276, 0.242, 0.128]      [0.129, 0.464]    [0.654, 0.145, 0.6, 0.111]  \n",
       "\n",
       "[2 rows x 17266 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mscoco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to a csv file\n",
    "df_mscoco.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f47be3683f59e8aeef879fff2fc5e330c3660c13104c735672053b830807840"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 ('clip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
